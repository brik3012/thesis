{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from __future__ import print_function # Use a function definition from future version (say 3.x from 2.7 interpreter)\n",
    "from PIL import Image\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import sys\n",
    "import cntk as C \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#da qui prendo sessioni\n",
    "listaMe2=list()\n",
    "with open('sessionLabelMe2.csv', 'r') as csvfile:\n",
    "     spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "     for row in spamreader:\n",
    "         listaMe2.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idMe2=list()\n",
    "labelMe2=np.array([])\n",
    "for i in range(len(listaMe2)):\n",
    "    if listaMe2[i][0][13]=='.' and (len(listaMe2[i][0])==20 or len(listaMe2[i][0])==19) :\n",
    "        idMe2.append(listaMe2[i][0][7:17])\n",
    "        labelMe2=np.append(labelMe2,int(listaMe2[i][0][18:]))\n",
    "    if listaMe2[i][0][12]=='.' :\n",
    "        idMe2.append(listaMe2[i][0][7:16])\n",
    "        labelMe2=np.append(labelMe2,int(listaMe2[i][0][17:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#traccio img bianche\n",
    "sid3=list()\n",
    "lab3=np.array([])\n",
    "for i in range(len(idMe2)):\n",
    "    if(labelMe2[i]==-1):\n",
    "        sid3.append(idMe2[i])\n",
    "        lab3=np.append(lab3,labelMe2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lista=list()\n",
    "with open('ClassificationNew.csv', 'r') as csvfile:\n",
    "     spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "     for row in spamreader:\n",
    "         lista.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "byteArrayFolder=\"./doveCreoFile\"\n",
    "data_dir=\"./trackTemp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sessionId=list()\n",
    "labels=np.array([])\n",
    "for i in range(len(lista)-1):\n",
    "    if lista[i+1][0][2]==',' and lista[i+1][0][7]==',':\n",
    "        sessionId.append(lista[i+1][0][3:7]+'.png')\n",
    "        labels=np.append(labels,int(lista[i+1][0][8]))\n",
    "    elif lista[i+1][0][2]==',' and lista[i+1][0][8]==',':\n",
    "        sessionId.append(lista[i+1][0][3:8]+'.png')\n",
    "        labels=np.append(labels,int(lista[i+1][0][9]))\n",
    "    elif lista[i+1][0][3]==',' and lista[i+1][0][9]==',':\n",
    "        sessionId.append(lista[i+1][0][4:9]+'.png')\n",
    "        labels=np.append(labels,int(lista[i+1][0][10]))\n",
    "    elif lista[i+1][0][4]==',' and lista[i+1][0][10]==',':\n",
    "        sessionId.append(lista[i+1][0][5:10]+'.png')\n",
    "        labels=np.append(labels,int(lista[i+1][0][11]))\n",
    "    elif lista[i+1][0][5]==',' and lista[i+1][0][11]==',':\n",
    "        sessionId.append(lista[i+1][0][6:11]+'.png')\n",
    "        labels=np.append(labels,int(lista[i+1][0][12]))\n",
    "    elif lista[i+1][0][6]==',' and lista[i+1][0][12]==',':\n",
    "        sessionId.append(lista[i+1][0][7:12]+'.png')\n",
    "        labels=np.append(labels,int(lista[i+1][0][13]))\n",
    "    else:#elif lista[i+1][0][6]==',' and lista[i+1][0][13]==',':\n",
    "        sessionId.append(lista[i+1][0][7:13]+'.png')\n",
    "        labels=np.append(labels,int(lista[i+1][0][14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctfTrainFile=os.path.join(byteArrayFolder, \"trainClass.txt\") \n",
    "ctfTestFile=os.path.join(byteArrayFolder, \"testClass.txt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imglist=os.listdir(data_dir)\n",
    "#imglist=os.listdir(os.path.join(\"..\", \"ImgTrack\"))\n",
    "for fichier in imglist[:]: # imgist[:] makes a copy of imglist.\n",
    "    if not(fichier.endswith(\".png\")):\n",
    "        imglist.remove(fichier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#controllo che ci siano nella cartella\n",
    "sid=list()\n",
    "lab=np.array([])\n",
    "for i in range(len(sessionId)):\n",
    "    for j in range(len(imglist)):\n",
    "        if sessionId[i]==imglist[j]:\n",
    "            sid.append(sessionId[i])\n",
    "            lab=np.append(lab,labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#devo togliere img bianche \n",
    "conta=0\n",
    "iVia=np.array([])\n",
    "for i in range(len(sid)):\n",
    "    for j in range(len(sid3)):\n",
    "        if sid[i]==sid3[j]:\n",
    "            #print(sid[i],lab[i])\n",
    "            iVia=np.append(iVia,i)\n",
    "            conta+=1\n",
    "#print(conta)\n",
    "sidCopy=sid[:]\n",
    "labCopy=np.array([])\n",
    "for u in range(len(iVia)):\n",
    "    sidCopy.remove(sid[int(iVia[u])])\n",
    "for t in range(len(sidCopy)):\n",
    "    for r in range(len(sid)):\n",
    "        if sidCopy[t]==sid[r]:\n",
    "            labCopy=np.append(labCopy,lab[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1659"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sid)-len(sidCopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4848, 1240, 591, 894)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(labCopy==0),sum(labCopy==1),sum(labCopy==2),sum(labCopy==3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labs = list(map(' '.join, np.eye(4, dtype=np.uint).astype(str)))\n",
    "imgWhite = os.path.join(data_dir, '27391.png')\n",
    "for j in range(len(sidCopy)):\n",
    "    if lab[j]==0:\n",
    "        rotationAngle=np.linspace(360//2,360,2)\n",
    "        for r in range(len(rotationAngle)):\n",
    "            imgfile = os.path.join(data_dir, sidCopy[j])\n",
    "            p=PIL.Image.open(imgfile)\n",
    "            white=PIL.Image.open(imgWhite)\n",
    "            white=white.resize((150,150))\n",
    "            white.paste(p,(25,25,125,125),p)\n",
    "            p_rot=white.rotate(rotationAngle[r])\n",
    "            p_new=p_rot.crop((5,5,145,145))\n",
    "            pw=PIL.Image.open(imgWhite)\n",
    "            pw=pw.resize((140,140))\n",
    "            pw.paste(p_new,(0,0),p_new)\n",
    "            p_end=pw.resize((100,100))\n",
    "            ch=(np.array(p_end)[:,:,0]).flatten()\n",
    "            ch_lab=np.append(ch,lab[j])\n",
    "            row_str = ch_lab.astype(str)#qui ci mette lo zero vicino al punto\n",
    "            label_str = labs[int(ch_lab[-1])]#legge 1.0 come stringa per quello ho messo int\n",
    "            feature_str = ' '.join(row_str[:-1])\n",
    "            numRandom=np.random.uniform(0,1)\n",
    "            if j==0 and r==0:\n",
    "                with open(ctfTrainFile, 'w') as f:\n",
    "                    f.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "                with open(ctfTestFile, 'w') as g:\n",
    "                    g.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "            else:   \n",
    "                if numRandom>0.25:\n",
    "                    with open(ctfTrainFile, 'a') as f:\n",
    "                        f.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "                else:\n",
    "                    with open(ctfTestFile, 'a') as g:\n",
    "                        g.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "    elif lab[j]==1:\n",
    "        rotationAngle=np.linspace(360//5,360,5)\n",
    "        for r in range(len(rotationAngle)):\n",
    "            imgfile = os.path.join(data_dir, sidCopy[j])\n",
    "            p=PIL.Image.open(imgfile)\n",
    "            white=PIL.Image.open(imgWhite)\n",
    "            white=white.resize((150,150))\n",
    "            white.paste(p,(25,25,125,125),p)\n",
    "            p_rot=white.rotate(rotationAngle[r])\n",
    "            p_new=p_rot.crop((5,5,145,145))\n",
    "            pw=PIL.Image.open(imgWhite)\n",
    "            pw=pw.resize((140,140))\n",
    "            pw.paste(p_new,(0,0),p_new)\n",
    "            p_end=pw.resize((100,100))\n",
    "            ch=(np.array(p_end)[:,:,0]).flatten()\n",
    "            ch_lab=np.append(ch,lab[j])\n",
    "            row_str = ch_lab.astype(str)#qui ci mette lo zero vicino al punto\n",
    "            label_str = labs[int(ch_lab[-1])]#legge 1.0 come stringa per quello ho messo int\n",
    "            feature_str = ' '.join(row_str[:-1])\n",
    "            numRandom=np.random.uniform(0,1)\n",
    "            if j==0 and r==0:\n",
    "                with open(ctfTrainFile, 'w') as f:\n",
    "                    f.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "                with open(ctfTestFile, 'w') as g:\n",
    "                    g.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "            else:   \n",
    "                if numRandom>0.25:\n",
    "                    with open(ctfTrainFile, 'a') as f:\n",
    "                        f.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "                else:\n",
    "                    with open(ctfTestFile, 'a') as g:\n",
    "                        g.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "    elif lab[j]==2:\n",
    "        rotationAngle=np.linspace(360//17,360,17)\n",
    "        for r in range(len(rotationAngle)):\n",
    "            imgfile = os.path.join(data_dir, sidCopy[j])\n",
    "            p=PIL.Image.open(imgfile)\n",
    "            white=PIL.Image.open(imgWhite)\n",
    "            white=white.resize((150,150))\n",
    "            white.paste(p,(25,25,125,125),p)\n",
    "            p_rot=white.rotate(rotationAngle[r])\n",
    "            p_new=p_rot.crop((5,5,145,145))\n",
    "            pw=PIL.Image.open(imgWhite)\n",
    "            pw=pw.resize((140,140))\n",
    "            pw.paste(p_new,(0,0),p_new)\n",
    "            p_end=pw.resize((100,100))\n",
    "            ch=(np.array(p_end)[:,:,0]).flatten()\n",
    "            ch_lab=np.append(ch,lab[j])\n",
    "            row_str = ch_lab.astype(str)#qui ci mette lo zero vicino al punto\n",
    "            label_str = labs[int(ch_lab[-1])]#legge 1.0 come stringa per quello ho messo int\n",
    "            feature_str = ' '.join(row_str[:-1])\n",
    "            numRandom=np.random.uniform(0,1)\n",
    "            if j==0 and r==0:\n",
    "                with open(ctfTrainFile, 'w') as f:\n",
    "                    f.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "                with open(ctfTestFile, 'w') as g:\n",
    "                    g.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "            else:   \n",
    "                if numRandom>0.25:\n",
    "                    with open(ctfTrainFile, 'a') as f:\n",
    "                        f.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "                else:\n",
    "                    with open(ctfTestFile, 'a') as g:\n",
    "                        g.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "    else:\n",
    "        rotationAngle=np.linspace(360//8,360,8)\n",
    "        for r in range(len(rotationAngle)):\n",
    "            imgfile = os.path.join(data_dir, sidCopy[j])\n",
    "            p=PIL.Image.open(imgfile)\n",
    "            white=PIL.Image.open(imgWhite)\n",
    "            white=white.resize((150,150))\n",
    "            white.paste(p,(25,25,125,125),p)\n",
    "            p_rot=white.rotate(rotationAngle[r])\n",
    "            p_new=p_rot.crop((5,5,145,145))\n",
    "            pw=PIL.Image.open(imgWhite)\n",
    "            pw=pw.resize((140,140))\n",
    "            pw.paste(p_new,(0,0),p_new)\n",
    "            p_end=pw.resize((100,100))\n",
    "            ch=(np.array(p_end)[:,:,0]).flatten()\n",
    "            ch_lab=np.append(ch,lab[j])\n",
    "            row_str = ch_lab.astype(str)#qui ci mette lo zero vicino al punto\n",
    "            label_str = labs[int(ch_lab[-1])]#legge 1.0 come stringa per quello ho messo int\n",
    "            feature_str = ' '.join(row_str[:-1])\n",
    "            numRandom=np.random.uniform(0,1)\n",
    "            if j==0 and r==0:\n",
    "                with open(ctfTrainFile, 'w') as f:\n",
    "                    f.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "                with open(ctfTestFile, 'w') as g:\n",
    "                    g.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "            else:   \n",
    "                if numRandom>0.25:\n",
    "                    with open(ctfTrainFile, 'a') as f:\n",
    "                        f.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "                else:\n",
    "                    with open(ctfTestFile, 'a') as g:\n",
    "                        g.write('|labels {} |features {}\\n'.format(label_str, feature_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#inizializzazioni variabili input\n",
    "num_classes = 4\n",
    "input_dim = 100*100\n",
    "\n",
    "input_dim_model = (1,100,100)\n",
    "x = C.input_variable(input_dim_model)\n",
    "y = C.input_variable(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creazione funzione per lettura del file, tramite il formato ctf ritornando un tipo MinibatchSource\n",
    "def create_reader(is_training):    \n",
    "    featureStream = C.io.StreamDef(field='features', shape=input_dim, is_sparse=False)   \n",
    "    labelStream = C.io.StreamDef(field='labels', shape=num_classes, is_sparse=False)\n",
    "\n",
    "    streams = C.io.StreamDefs(labels = labelStream, features = featureStream)\n",
    "\n",
    "    if is_training:\n",
    "        path = ctfTrainFile\n",
    "    else:\n",
    "        path = ctfTestFile\n",
    "    \n",
    "    deserializer = C.io.CTFDeserializer(path, streams)         \n",
    "\n",
    "    mbs = C.io.MinibatchSource(deserializer, randomize = is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)\n",
    "    #se son nel training INFINITELY_REPEAT permettera di coninuare a rigirare nel training all'infinito(decidero io num_minibatch\n",
    "    #e size), se son nel test voglio che si fermi una volta finiti(con num_minibatch e size) tutti gli elementi del testSet\n",
    "    return mbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = create_reader(True)\n",
    "test = create_reader(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#modello di CNN\n",
    "def create_model(features):\n",
    "    with C.layers.default_options(init=C.glorot_uniform(), activation=C.relu):\n",
    "        h = features\n",
    "        h = C.layers.Convolution((5,5), 8,strides=(2,2), pad=True,name='first_conv')(h)\n",
    "        h = C.layers.MaxPooling((10,10), strides=(2,2),name='first_max')(h)\n",
    "        h = C.layers.Convolution((5,5), 16,strides=(2,2), pad=True,name='second_conv')(h)\n",
    "        h = C.layers.MaxPooling((10,10), strides=(2,2),name='second_max')(h)\n",
    "        r = C.layers.Dense(num_classes, activation=None,name='classify')(h)\n",
    "    return r\n",
    "#per far saltare fuori cosa succede in mezzo potrei far tornare l'h dopo il primo MaxPooling, modificando questa funzione e la\n",
    "#sua chiamata a funzione associata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creazione funzioni di perdita e classficazione errore \n",
    "def create_criterion_function(model, labels):\n",
    "    loss = C.cross_entropy_with_softmax(model, labels)\n",
    "    errs = C.classification_error(model, labels)\n",
    "    return loss, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creazione funzione per la stampa, stampa con frequenza prestabilita il numero del minibatch in questione, perdita ed errore\n",
    "def print_training_progress(trainer, mb, frequency, verbose=1):\n",
    "    training_loss = \"NA\"\n",
    "    eval_error = \"NA\"\n",
    "    if mb%frequency == 0:\n",
    "        training_loss = trainer.previous_minibatch_loss_average\n",
    "        eval_error = trainer.previous_minibatch_evaluation_average\n",
    "        if verbose: \n",
    "            print (\"Minibatch: {0}, Loss: {1:.4f}, Error: {2:.2f}%\".format(mb, training_loss, eval_error*100))  \n",
    "    return mb, training_loss, eval_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalizzazione dei dati ed impostazione del modello\n",
    "x_norm=C.element_times(1.0/255.0,x)\n",
    "z=create_model(x_norm)\n",
    "#impostazione perdita ed errore\n",
    "loss, label_error = create_criterion_function(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#inizializzazione di learning_rate e sua schedule,minibatch_size, momentum, modello di ottimizzazione e numero di minibatch del\n",
    "#training, circa 10 volte il train(circa 8100 elementi) quindi 8100/64=1265\n",
    "learning_rate = 0.3\n",
    "lr_schedule = C.learning_rate_schedule(learning_rate, C.UnitType.minibatch)\n",
    "minibatch_size =64\n",
    "momentum_time_constant = C.momentum_as_time_constant_schedule(-minibatch_size/np.log(0.9))\n",
    "learner = C.adam(z.parameters, lr = lr_schedule, momentum = momentum_time_constant)\n",
    "num_minibatches_to_train =1265*4#*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#impostazione trainer\n",
    "trainer = C.Trainer(z, (loss, label_error), [learner])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mapping dei dati nelle variaibli d'input\n",
    "input_map={\n",
    "        y  : train.streams.labels,\n",
    "        x  : train.streams.features\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch: 0, Loss: 1.3823, Error: 60.94%\n",
      "Minibatch: 250, Loss: 1.3149, Error: 60.94%\n",
      "Minibatch: 500, Loss: 1.2647, Error: 56.25%\n",
      "Minibatch: 750, Loss: 1.2181, Error: 57.81%\n",
      "Minibatch: 1000, Loss: 1.3077, Error: 64.06%\n",
      "Minibatch: 1250, Loss: 1.1691, Error: 56.25%\n",
      "Minibatch: 1500, Loss: 1.3216, Error: 60.94%\n",
      "Minibatch: 1750, Loss: 1.1799, Error: 53.12%\n",
      "Minibatch: 2000, Loss: 1.2763, Error: 54.69%\n",
      "Minibatch: 2250, Loss: 1.1228, Error: 50.00%\n",
      "Minibatch: 2500, Loss: 1.0487, Error: 42.19%\n",
      "Minibatch: 2750, Loss: 1.2045, Error: 57.81%\n",
      "Minibatch: 3000, Loss: 1.2082, Error: 54.69%\n",
      "Minibatch: 3250, Loss: 1.1654, Error: 51.56%\n",
      "Minibatch: 3500, Loss: 1.3100, Error: 60.94%\n",
      "Minibatch: 3750, Loss: 1.0835, Error: 50.00%\n",
      "Minibatch: 4000, Loss: 1.1940, Error: 53.12%\n",
      "Minibatch: 4250, Loss: 1.1529, Error: 57.81%\n",
      "Minibatch: 4500, Loss: 1.1810, Error: 56.25%\n",
      "Minibatch: 4750, Loss: 1.1397, Error: 59.38%\n",
      "Minibatch: 5000, Loss: 1.1494, Error: 56.25%\n"
     ]
    }
   ],
   "source": [
    "#ciclo in cui si svolge il tutto\n",
    "for i in range(int(num_minibatches_to_train)):\n",
    "    data=train.next_minibatch(minibatch_size, input_map=input_map)#return mapping of stream information to MinibatchData\n",
    "    #Input('Input3', [#], [2 x 100 x 100]): MinibatchData(data=Value([64 x 1 x 20000], la struttura rimane [2x100x100] ma con i\n",
    "    #dati dentro mappati\n",
    "    trainer.train_minibatch(data)\n",
    "    print_training_progress(trainer, i, 250, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mapping per il test\n",
    "input_map = {\n",
    "        y  : test.streams.labels,\n",
    "        x  : test.streams.features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#circa 2700 elementi nel test, per star sicuro ne guardo 2500 facendo 25 minibatch di taglia 100\n",
    "test_minibatch_size =100\n",
    "num_samples=7500\n",
    "num_minibatches_to_test =num_samples // test_minibatch_size\n",
    "test_result = 0.0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test error: 49.24%\n"
     ]
    }
   ],
   "source": [
    "#valuto testSet e calcolo errore\n",
    "for i in range(num_minibatches_to_test):\n",
    "    data = test.next_minibatch(test_minibatch_size, input_map=input_map)\n",
    "    eval_error = trainer.test_minibatch(data)\n",
    "    test_result = test_result + eval_error \n",
    "print(\"Average test error: {0:.2f}%\".format(test_result*100 / num_minibatches_to_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solo label 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctfTrainFile=os.path.join(byteArrayFolder, \"trainClass01.txt\") \n",
    "ctfTestFile=os.path.join(byteArrayFolder, \"testClass01.txt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labs = list(map(' '.join, np.eye(2, dtype=np.uint).astype(str)))\n",
    "imgWhite = os.path.join(data_dir, '27391.png')\n",
    "for j in range(len(sidCopy)):\n",
    "    if lab[j]==0:\n",
    "        rotationAngle=np.linspace(360//2,360,2)\n",
    "        for r in range(len(rotationAngle)):\n",
    "            imgfile = os.path.join(data_dir, sidCopy[j])\n",
    "            p=PIL.Image.open(imgfile)\n",
    "            white=PIL.Image.open(imgWhite)\n",
    "            white=white.resize((150,150))\n",
    "            white.paste(p,(25,25,125,125),p)\n",
    "            p_rot=white.rotate(rotationAngle[r])\n",
    "            p_new=p_rot.crop((5,5,145,145))\n",
    "            pw=PIL.Image.open(imgWhite)\n",
    "            pw=pw.resize((140,140))\n",
    "            pw.paste(p_new,(0,0),p_new)\n",
    "            p_end=pw.resize((100,100))\n",
    "            ch=(np.array(p_end)[:,:,0]).flatten()\n",
    "            ch_lab=np.append(ch,lab[j])\n",
    "            row_str = ch_lab.astype(str)#qui ci mette lo zero vicino al punto\n",
    "            label_str = labs[int(ch_lab[-1])]#legge 1.0 come stringa per quello ho messo int\n",
    "            feature_str = ' '.join(row_str[:-1])\n",
    "            numRandom=np.random.uniform(0,1)\n",
    "            if j==0 and r==0:\n",
    "                with open(ctfTrainFile, 'w') as f:\n",
    "                    f.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "                with open(ctfTestFile, 'w') as g:\n",
    "                    g.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "            else:   \n",
    "                if numRandom>0.25:\n",
    "                    with open(ctfTrainFile, 'a') as f:\n",
    "                        f.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "                else:\n",
    "                    with open(ctfTestFile, 'a') as g:\n",
    "                        g.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "    elif lab[j]==1:\n",
    "        rotationAngle=np.linspace(360//5,360,5)\n",
    "        for r in range(len(rotationAngle)):\n",
    "            imgfile = os.path.join(data_dir, sidCopy[j])\n",
    "            p=PIL.Image.open(imgfile)\n",
    "            white=PIL.Image.open(imgWhite)\n",
    "            white=white.resize((150,150))\n",
    "            white.paste(p,(25,25,125,125),p)\n",
    "            p_rot=white.rotate(rotationAngle[r])\n",
    "            p_new=p_rot.crop((5,5,145,145))\n",
    "            pw=PIL.Image.open(imgWhite)\n",
    "            pw=pw.resize((140,140))\n",
    "            pw.paste(p_new,(0,0),p_new)\n",
    "            p_end=pw.resize((100,100))\n",
    "            ch=(np.array(p_end)[:,:,0]).flatten()\n",
    "            ch_lab=np.append(ch,lab[j])\n",
    "            row_str = ch_lab.astype(str)#qui ci mette lo zero vicino al punto\n",
    "            label_str = labs[int(ch_lab[-1])]#legge 1.0 come stringa per quello ho messo int\n",
    "            feature_str = ' '.join(row_str[:-1])\n",
    "            numRandom=np.random.uniform(0,1)\n",
    "            if j==0 and r==0:\n",
    "                with open(ctfTrainFile, 'w') as f:\n",
    "                    f.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "                with open(ctfTestFile, 'w') as g:\n",
    "                    g.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "            else:   \n",
    "                if numRandom>0.25:\n",
    "                    with open(ctfTrainFile, 'a') as f:\n",
    "                        f.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "                else:\n",
    "                    with open(ctfTestFile, 'a') as g:\n",
    "                        g.write('|labels {} |features {}\\n'.format(label_str, feature_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#inizializzazioni variabili input\n",
    "num_classes = 2\n",
    "input_dim = 100*100\n",
    "\n",
    "input_dim_model = (1,100,100)\n",
    "x = C.input_variable(input_dim_model)\n",
    "y = C.input_variable(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creazione funzione per lettura del file, tramite il formato ctf ritornando un tipo MinibatchSource\n",
    "def create_reader(is_training):    \n",
    "    featureStream = C.io.StreamDef(field='features', shape=input_dim, is_sparse=False)   \n",
    "    labelStream = C.io.StreamDef(field='labels', shape=num_classes, is_sparse=False)\n",
    "\n",
    "    streams = C.io.StreamDefs(labels = labelStream, features = featureStream)\n",
    "\n",
    "    if is_training:\n",
    "        path = ctfTrainFile\n",
    "    else:\n",
    "        path = ctfTestFile\n",
    "    \n",
    "    deserializer = C.io.CTFDeserializer(path, streams)         \n",
    "\n",
    "    mbs = C.io.MinibatchSource(deserializer, randomize = is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)\n",
    "    #se son nel training INFINITELY_REPEAT permettera di coninuare a rigirare nel training all'infinito(decidero io num_minibatch\n",
    "    #e size), se son nel test voglio che si fermi una volta finiti(con num_minibatch e size) tutti gli elementi del testSet\n",
    "    return mbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = create_reader(True)\n",
    "test = create_reader(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#due modelli scelti alla fine del tuning\n",
    "def create_model(features):\n",
    "    with C.layers.default_options(init=C.glorot_uniform(), activation=C.relu):\n",
    "        h = features\n",
    "        h = C.layers.Convolution((3,3), 8,strides=(2,2), pad=True,name='first_conv')(h)\n",
    "        h = C.layers.MaxPooling((2,2), strides=(2,2),name='first_max')(h)\n",
    "        h = C.layers.Convolution((3,3), 16,strides=(2,2), pad=True,name='second_conv')(h)\n",
    "        h = C.layers.MaxPooling((2,2), strides=(2,2),name='second_max')(h)\n",
    "        h = C.layers.Dense(16)(h)\n",
    "        r = C.layers.Dense(num_classes, activation=None,name='classify')(h)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(features):\n",
    "    with C.layers.default_options(init=C.glorot_uniform(), activation=C.relu):\n",
    "        h = features\n",
    "        h = C.layers.Convolution((5,5), 8,strides=(1,1), pad=True,name='first_conv')(h)\n",
    "        h = C.layers.MaxPooling((2,2), strides=(2,2),name='first_max')(h)\n",
    "        h = C.layers.Convolution((5,5), 16,strides=(1,1), pad=True,name='second_conv')(h)\n",
    "        h = C.layers.MaxPooling((2,2), strides=(2,2),name='second_max')(h)\n",
    "        h = C.layers.Convolution((5,5), 32,strides=(1,1), pad=True,name='third_conv')(h)\n",
    "        h = C.layers.MaxPooling((2,2), strides=(2,2),name='third_max')(h)\n",
    "        h = C.layers.Convolution((5,5), 64,strides=(1,1), pad=True,name='fourth_conv')(h)\n",
    "        h = C.layers.MaxPooling((2,2), strides=(2,2),name='fourth_max')(h)\n",
    "        h = C.layers.Convolution((5,5), 128,strides=(1,1), pad=True,name='fifth_conv')(h)\n",
    "        h = C.layers.MaxPooling((2,2), strides=(2,2),name='fifth_max')(h)\n",
    "        h = C.layers.Dropout(0.5)(h)\n",
    "        r = C.layers.Dense(num_classes, activation=None,name='classify')(h)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creazione funzioni di perdita e classficazione errore \n",
    "def create_criterion_function(model, labels):\n",
    "    loss = C.cross_entropy_with_softmax(model, labels)\n",
    "    errs = C.classification_error(model, labels)\n",
    "    return loss, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creazione funzione per la stampa, stampa con frequenza prestabilita il numero del minibatch in questione, perdita ed errore\n",
    "def print_training_progress(trainer, mb, frequency, verbose=1):\n",
    "    training_loss = \"NA\"\n",
    "    eval_error = \"NA\"\n",
    "    if mb%frequency == 0:\n",
    "        training_loss = trainer.previous_minibatch_loss_average\n",
    "        eval_error = trainer.previous_minibatch_evaluation_average\n",
    "        if verbose: \n",
    "            print (\"Minibatch: {0}, Loss: {1:.4f}, Error: {2:.2f}%\".format(mb, training_loss, eval_error*100))  \n",
    "    return mb, training_loss, eval_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalizzazione dei dati ed impostazione del modello\n",
    "x_norm=C.element_times(1.0/256.0,x)\n",
    "z=create_model(x_norm)\n",
    "#impostazione perdita ed errore\n",
    "loss, label_error = create_criterion_function(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#inizializzazione di learning_rate e sua schedule,minibatch_size, momentum, modello di ottimizzazione e numero di minibatch del\n",
    "#training, circa 10 volte il train(circa 8100 elementi) quindi 8100/64=1265\n",
    "learning_rate = 0.1\n",
    "lr_schedule = C.learning_rate_schedule(learning_rate, C.UnitType.minibatch)\n",
    "minibatch_size =64\n",
    "momentum_time_constant = C.momentum_as_time_constant_schedule(-minibatch_size/np.log(0.9))\n",
    "learner = C.adam(z.parameters, lr = lr_schedule, momentum = momentum_time_constant)\n",
    "num_minibatches_to_train =150000/minibatch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#impostazione trainer\n",
    "trainer = C.Trainer(z, (loss, label_error), [learner])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mapping dei dati nelle variaibli d'input\n",
    "input_map={\n",
    "        y  : train.streams.labels,\n",
    "        x  : train.streams.features\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch: 0, Loss: 0.6864, Error: 39.06%\n",
      "Minibatch: 234, Loss: 0.6180, Error: 35.94%\n",
      "Minibatch: 468, Loss: 0.2889, Error: 12.50%\n",
      "Minibatch: 702, Loss: 0.3227, Error: 14.06%\n",
      "Minibatch: 936, Loss: 0.4890, Error: 17.19%\n",
      "Minibatch: 1170, Loss: 0.2665, Error: 14.06%\n",
      "Minibatch: 1404, Loss: 0.2515, Error: 10.94%\n",
      "Minibatch: 1638, Loss: 0.2491, Error: 14.06%\n",
      "Minibatch: 1872, Loss: 0.1631, Error: 6.25%\n",
      "Minibatch: 2106, Loss: 0.2274, Error: 7.81%\n",
      "Minibatch: 2340, Loss: 0.3679, Error: 14.06%\n"
     ]
    }
   ],
   "source": [
    "#ciclo in cui si svolge il tutto\n",
    "for i in range(int(num_minibatches_to_train)):\n",
    "    data=train.next_minibatch(minibatch_size, input_map=input_map)#return mapping of stream information to MinibatchData\n",
    "    #Input('Input3', [#], [2 x 100 x 100]): MinibatchData(data=Value([64 x 1 x 20000], la struttura rimane [2x100x100] ma con i\n",
    "    #dati dentro mappati\n",
    "    trainer.train_minibatch(data)\n",
    "    print_training_progress(trainer, i, num_minibatches_to_train//10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mapping per il test\n",
    "input_map = {\n",
    "        y  : test.streams.labels,\n",
    "        x  : test.streams.features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#circa 2700 elementi nel test, per star sicuro ne guardo 2500 facendo 25 minibatch di taglia 100\n",
    "test_minibatch_size =100\n",
    "num_samples=4000\n",
    "num_minibatches_to_test =num_samples // test_minibatch_size\n",
    "test_result = 0.0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test error: 9.40%\n"
     ]
    }
   ],
   "source": [
    "#valuto testSet e calcolo errore\n",
    "for i in range(num_minibatches_to_test):\n",
    "    data = test.next_minibatch(test_minibatch_size, input_map=input_map)\n",
    "    eval_error = trainer.test_minibatch(data)\n",
    "    test_result = test_result + eval_error \n",
    "print(\"Average test error: {0:.2f}%\".format(test_result*100 / num_minibatches_to_test)) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
